---
title: "Untitled"
format: gfm
execute: 
  echo: false
  warning: false
  message: false
  cache: false
filters:
  - ../../_extensions/pandoc-ext/abstract-section/abstract-section.lua
  - ../../_extensions/mloubout/critic-markup/critic-markup.lua
  - ../../_extensions/ute/search-replace/search-replace.lua
search-replace:
  +S2: ACCESS-S2
  +S1: ACCESS-S1
  +CDR: CDR
bibliography: references.bib
editor: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
library(lubridate)
library(ggplot2)
library(data.table)
library(metR)
library(rcdo)
library(tagger)

cdo_options_set("-L")
source(here::here("R/functions.R"))
source(here::here("R/datasets.R"))
source(here::here("R/ggplot.R"))
```

# Abstract

balbalbal

# Introduction

{==**Antarctic sea ice general description**.
Seasonality, trends.==}

{==**Importance**.
Impacts on life.
Potential impacts on weather.
Impacts on climate.
Impacts on ocean circulation.(Justify why it's important to study and understand)==}

{==**Prediction systems.** Why is it important: operations {\>\>Discuss with Phil\<\<}; science needs (we need good models).
What is available.
Discussion on S1 {\>\>Can we discuss previous S1 results?
Laura's paper is not public.\<\<}==}

{==**Objective.** Evaluate S2.==}

# Data and methods

All datasets are regrided using bilinear interpolation to a common grid, which is a polar sterographic grid with approximatedly equal area of 25km².

## Description of the model

+S2 is the next saeasonal prediction system after ACCESS-S1.
It uses virtually the same exact model configuration except for some model versions being different.
The main difference are the initial conditions.
While S1 used initial conditions from the UK Met Office, S2 uses the Bureau's own system.
{== Description of the system ==}{\>\>Atmosphere and ocean.
Highlight no ice data assimilation.
Highligh that the hope is that ice will respond to SST/atmosphere DA\<\<}

For evaluation we use hindcst for the period 1981--2023{\>\>Check\<\<}.
Anomalies will be taken with respect to the 1981--2011 climatology computed from the reanalysis.
Climatology is smoothed with a 11 day running mean.

## Verification datasets

There is not a lot of data on sea ice properties, especially for things like thickness, age, etc.
However there are relatively reliable satellite-derived estimates of sea ice concentration, which estimates the proportion of each grid area that is covered with ice.
These products are not perfect and there still exists a fair bit of observation al uncertainty.
To account for this uncertainty we use multiple datasets.

### Bootstrap

{\>\>From https://nsidc.org/data/nsidc-0079/versions/4\<\<} This sea ice concentration data set was derived using measurements from the Scanning Multichannel Microwave Radiometer (SMMR) on the Nimbus-7 satellite and from the Special Sensor Microwave/Imager (SSM/I) sensors on the Defense Meteorological Satellite Program's (DMSP) -F8, -F11, and -F13 satellites.
Measurements from the Special Sensor Microwave Imager/Sounder (SSMIS) aboard DMSP-F17 are also included.
The data set has been generated using the Advanced Microwave Scanning Radiometer - Earth Observing System (AMSR-E) Bootstrap Algorithm with daily varying tie-points.
Daily (every other day prior to July 1987) and monthly data are available for both the north and south polar regions.
Data are gridded on the SSM/I polar stereographic grid (25 x 25 km) and provided in two-byte integer format.
Data coverage began on 01 November 1978 and is ongoing through the most current processing, with updated data processed several times annually.

[@comiso2023]

### NASA Team

{==missing==}

### CDR

NOAA/NSIDC's Climate Data Record V4 combines the Bootstrap and NASA Team estimates in an attempt to overcome each algorithm's weaknesses.
{\>\>More detail on how are they combined and their properties.\<\<} As such, it is is not a truly independent dataset.

Meier, W. N., F. Fetterer, A. K. Windnagel, and S.
Stewart.
2021.
NOAA/NSIDC Climate Data Record of Passive Microwave Sea Ice Concentration, Version 4.
\[Indicate subset used\].
Boulder, Colorado USA. NSIDC: National Snow and Ice Data Center https://doi.org/10.7265/efmz-2t65.
\[Date Accessed\] {\>\>Add to zotero\<\<}

### ERA5

{==From the CDS websiste:==} ERA5 is the fifth generation ECMWF reanalysis for the global climate and weather for the past 8 decades.
Data is available from 1940 onwards.
ERA5 replaces the ERA-Interim reanalysis.

This parameter is the fraction of a grid box which is covered by sea ice.
Sea ice can only occur in a grid box which includes ocean or inland water according to the land-sea mask and lake cover, at the resolution being used.
This parameter can be known as sea-ice (area) fraction, sea-ice concentration and more generally as sea-ice cover.
In ERA5, sea-ice cover is given by two external providers.
Before 1979 the HadISST2 dataset is used.
From 1979 to August 2007 the OSI SAF (409a) dataset is used and from September 2007 the OSI SAF oper dataset is used.
Sea ice is frozen sea water which floats on the surface of the ocean.
Sea ice does not include ice which forms on land such as glaciers, icebergs and ice-sheets.
It also excludes ice shelves which are anchored on land, but protrude out over the surface of the ocean.
These phenomena are not modelled by the IFS.
Long-term monitoring of sea ice is important for understanding climate change.
Sea ice also affects shipping routes through the polar regions.

{\>\>Why is ERA5 better or worse than satellites?\<
\<}

## Error measures

For evaluation purposes, we use a series of measures.

### Sea ice extent

Sea Ice Extent is defined as the area of ocean covered with at least 15% ice.
This threshold is motivated by the limitations in satellite retrieval, which is increasingly unreliable for low sea ice conditions.

Sea Ice Extent is a rough global measure, but a model could have relatively accurate extent of ice but with different distributions.
We use two other measures to account for these errors.

We compute Root Mean Square Error of sea ice concentration anomalies.

We also compute the Integrated Ice Edge Error (IIEE) [@goessling2016].
This is defined as the area in which the model misspredicts sea ice concentration being above or belog 15% ice.
That is, dichotomise sea ice concentration into areas with more and less than 15% sea ice both in the forecast and observations; the IIEE is the area in which forecast and observations differ.

# Results and discussion

## Reanalysis

### Bias

```{r datasets}
datasets <- list(cdr = CDR(),
                 bt = BT(),
                 era5 = ERA5()
)
which_dataset <- "cdr"
```

```{r extent_daily}
extent_daily <- datasets |>
  lapply(extent) |>
  lapply(\(x) ReadNetCDF(x, "aice")) |>
  rbindlist(idcol = "dataset") |>
  _[, let(lon = NULL, lat = NULL)]
```

```{r}
extent_climatology <- extent_daily |>  
  copy() |>
  _[aice == 0, aice := NA] |> 
  _[!(month(time) == 2 & mday(time) == 29)] |> 
  _[, time := update(time, year = 2001)] |> 
  _[, median_ci(aice), by = .(time, dataset)] 

```

```{r hindcast_extent}
hindcast_extent <- rbind(S1 = readRDS(here::here("data/derived/S1_hindcast_extent.Rds")),
                         S2 = readRDS(here::here("data/derived/S2_hindcast_extent.Rds")), 
                         idcol = "model") |>
  _[, model := relevel(factor(model), "S2")] |> 
  _[, lag := as.numeric(as.Date(time) - forecast_time)] |> 
  _[lag > 0]
```

```{r fig-hindcast-extent}
#| fig-cap: Median sea ice extent for al hindcasts initialised the first of the month for +S2 and +S1 in colours representing the start month. In black, the 
hindcast_extent |> 
  _[, median_ci(aice), by = .(forecast_time = update(forecast_time, year = 2001),
                              lag = as.numeric(as.Date(time) - forecast_time),
                              model)] |>
  _[, time := forecast_time + lag] |>
  _[, time2 := update(time, year = 2001)] |>
  _[, month := lubridate::month(forecast_time, label = TRUE)] |>
  # _[]
  ggplot(aes(time2, mid)) +
  geom_line(data = extent_climatology[dataset == which_dataset], 
            aes(x = as.Date(time),
                group = dataset)) + 
  geom_line(aes(color = month, group = interaction(forecast_time, time != time2))) +
  
  geom_point(data = \(x) x[mday(time) == 2, .SD[which.max(lag)], by = .(forecast_time, model)], 
             aes(fill = month), 
             shape = 24, size = 2.2) +
  
  geom_point(data = \(x) x[lag == 1], aes(fill = month), 
             shape = 21, size = 2) +
  
  scale_x_date(NULL, date_breaks = "1 month", 
               date_labels = "%b", expand = c(0, 0)) +
  scale_y_continuous(NULL, labels = labels_extent) +
  scale_color_manual(values = cetcolor::cet_pal(12, name = "c2"), 
                     aesthetics = c("fill", "color"), guide = "none") +
  facet_wrap(~ model, ncol = 1) +
  tag_facets() 
```

@fig-hindcast-extent a shows the seasonal cycle of Sea Ice Extent for the +S2 hindcast and `r length(datasets)-1` observational datasets.
+S2 shows a severe low extent bias, especially in the late summer-early autumn.
This is due primarily to a faster and longer melt season between January and March and slower growth during March and April This is then balanced with faster growth between May and July ([Fig. @fig-mean-growth]).
This bias is common in climate models \[ref!\]
and it's been linked to xxxx??

Comparing +S2 with +S1, the latter has a smaller bias, especially at low lags ([Fig. @fig-hindcast-extent b]) even though the typical growth rates are very similar between both models ([Fig. @fig-mean-growth]).
At larger lags, +S1's bias in summer and autumn is very similar to +S2\`s.
This suggests that this lower sea ice state is closer to the models' equilibrium, indicating that it is an issue with model formulation that was being corrected by the data assimilation system in +S1.

At long lags, sea ice extent loses most of the initial condition memory and reverts to the model's preferred equilibrium state.
Therefore we can estimate the latter using the hindcasts with the largest possible lag, which is shown in triangles in @fig-hindcast-extent for the same dates as the initial conditions.
The difference between the two is the effect of the data assimilation.

The equilibrium of +S1 and +S2 is very similar (comparing the triangles in each panel in [Fig. @fig-hindcast-extent]), owing to both having the same model formulation.
From June to October, in +S2 circles move away from triangles and towards observations, indicating that the information from the ocean and atmosphere data assimilation is getting to sea ice and affecting the initial conditions.
The rest of the year, there is little if any difference between circles and triangles in +S2, indicating that almost no data assimilation is taking place and the sea ice component of the model is virtually free-running.

```{r fig-mean-growth}
#| fig-cap: Median daily sea ice extent growth of +S1 and +S2 hindcasts and observations. Values are smoothed with a 2-degree loess smooth with a 30 day window. 

dif_hindcast <- hindcast_extent |> 
  copy() |> 
  _[order(time)] |> 
  _[, dif := c(NA, diff(aice)/diff(as.numeric(as.Date(time)))), by = .(model, forecast_time, member)] |> 
  _[, median_ci(dif), by = .(model, time = update(time, year = 2000))] 


extent_daily |> 
  _[order(time)] |> 
  _[, dif := c(NA, diff(aice)/diff(as.numeric(as.Date(time)))), by = .(dataset)] |> 
  _[, median_ci(dif), by = .(dataset, time = update(time, year = 2000))] |> 
  _[dataset == which_dataset] |> 
  ggplot(aes(time, mid)) +
  geom_hline(yintercept = 0, color = "gray50", linewidth = 0.2) +
  geom_smooth(aes(group = dataset, color = dataset),
              span = 30/366, linewidth = 0.5, se = FALSE, n = 366)  +
  geom_smooth(data = dif_hindcast,
              aes(color = model), span = 30/366, linewidth = 0.5, se = FALSE, n = 366) +
  scale_x_datetime(NULL, date_breaks = "1 month", 
                   date_labels = "%b", expand = c(0, 0)) +
  scale_y_continuous(NULL, labels = labels_extent) +
  scale_color_models
```

```{r climatology}
climatologies <- c(datasets,
                   S2 = S2_reanalysis()) |>
  lapply(\(x) climatology(x) |>
           cdo_ymonmean() |> 
           cdo_execute()
  ) |>
  lapply(\(x) ReadNetCDF(x, "aice")) |>
  rbindlist(idcol = "model") 
```

```{r fig-bias}
#| fig-width: 9
#| fig-height: 6
#| fig-cap: +S2 reanalysis sea ice concentration bias compared with NSIDC sea ice concentration.

climatologies |> 
  _[model %in% c("S2", which_dataset)] |> 
  dcast(time + xgrid + ygrid ~ model, value.var = "aice") |> 
  setnames(which_dataset, "obs") |> 
  ggplot(aes(xgrid, ygrid)) +
  geom_contour_fill(aes(z = S2 - obs, fill = after_stat(level)), 
                    breaks = AnchorBreaks(binwidth = 0.1, exclude = 0)) +
  scale_fill_divergent_discretised(paste0("Bias with respect to ", labels_models[which_dataset])) +
  geomcoord_antarctica +
  geom_antarctica_fill +
  facet_wrap(~ lubridate::month(time, label = TRUE)) +
  wide_legend +
  tag_facets()
```



@fig-bias shows the difference in monthly mean sea ice concentrations between +CDR and +S2 reanalysis.
From October to May, the model underestimates sea ice concentrations pretty much everywhere there is ice except for the deep Weddell Sea in April and May, where sea ice concentrations saturate to 1.
In winter, the differences are mostly on the sea ice edge, with slight positive bias in XXX and negative bias around the Indian Ocean sector.

### Anomalies

{==intro connecting subsections==}

```{r fig-extent-anom}
#| fig-cap: Sea ice extent anomalies for +S1 and +S2 (black) and +CDR (blue). 

months_difference <- function(x, y) {
  lubridate::interval(y, x) %/% months(1)
}

monthly_extent <- extent_daily |> 
  _[aice == 0, aice := NA]  |> 
  _[, .(aice = mean(aice)), by = .(dataset, time = as.Date(round_date(time, "month")))] |>
  _[, aice := Anomaly(aice, year(time) %between% c(1981, 2011), na.rm = TRUE), 
    by = .(month(time), dataset)] 

N <- uniqueN(monthly_extent$time)

hindcast_extent |> 
  copy() |> 
  # _[model == "S2"] |> 
  _[, aice := aice - mean(aice[year(time) %between% c(1981, 2011)]), 
    by = .(lag, model, time = update(time, year = 2000))] |> 
  _[, .(aice = mean(aice)), by = .(model, forecast_time, time = as.Date(round_date(time, "month")))] |> 
  _[, lag := months_difference(time, forecast_time) + 1] |> 
  _[lag %in% c(1, 3, 5, 7)] |> 
  ggplot(aes(time, aice)) +
  geom_line(data = monthly_extent[year(time) <= max(year(hindcast_extent$time))] |> 
              _[dataset == which_dataset],
            aes(group = dataset, color = dataset)) +
  # geom_smooth(data = monthly_extent[year(time) <= max(year(hindcast_extent$time))] |> 
  #               _[dataset == "cdr"], 
  #             aes(group = dataset, color = dataset),
  #             se = FALSE, span = 10*12/N, n = 366) +
  geom_line(aes(color = model))  +
  # geom_smooth(aes(color = model), se = FALSE, span = 10*12/N, n = 366) +
  scale_y_continuous(NULL,
                     labels = labels_extent) +
  scale_x_date(NULL, expand = c(0, 0)) +
  facet_grid(lag ~ model, labeller = labeller(lag = \(x) paste0("Lag: ", x))) +
  scale_color_models
```

@fig-extent-anom shows monthly sea ice extent anomalies forecasted at selected lags.
The anomalies in this case were computed with respect of the climatology of each lag, which is a way of bias-correction.
Compared with +S1, +S2 anomaly forecast is relatively poor even in the first month, which stays relatively skilful even at lag 3.
+S2 shows much bigger variability than observations, with dramatic lows between 1995 and 2007 and highs between 2007 and 2015.

{\>\>Add regional extents?\<
\<}

### RMSE

To study +S2 forecasts quantitatively, we compute error measures for all hindcasts started on the 1st of every month.

```{r errors}
errors <- rbind(
  readRDS(here::here("data/derived/rmse.Rds")) |>
    _[version != "S1"], 
  readRDS(here::here("data/derived/iiee.Rds"))
) |>
  _[value < 0.01, value := NA] |> 
  _[value > 3e13, value := NA] |> 
  _[, time := as.Date(time)] |> 
  _[, lag := as.numeric(time - time_forecast)] |> 
  _[lag > 0] |> 
  _[!(month(time_forecast) == 1 & member == "07" & version == "S1")]  # This member is wrong

```

```{r fig-rmse}
#| fig-cap: Median and 95% coverage of sea ice concentration anomalies RMSE as a function of forecast lag for all forecast initialised on the first of each month compared with a reference forecast of persistence of anomalies. 
#| fig.height: 5
#| fig.width: 9

month_from_lag <- function(day = 1, step = 2) {
  force(day)
  force(step)
  function(x) {
    unique(x[, .(lag, month)])[, time := make_date(month = month, day = 1) + lag] |> 
      _[mday(time) == day, .(lag, month, 
                             month2 = lubridate::month(time, label = TRUE)
      )] |> 
      _[, .SD[((seq_len(.N) + 1) %% step) == 0], by = month]
  }
}

errors |> 
  _[measure == "rmse"] |>
  _[obs_dataset == which_dataset] |>
  _[, median_ci(value), 
    by = .(lag, version, measure, month(time_forecast), obs_dataset)] |> 
  _[version == "persistence", version := obs_dataset] |> 
  ggplot(aes(lag, mid)) +
  
  geom_vline(data = month_from_lag(1, 1), aes(xintercept = lag), 
             colour = "gray50", linewidth = 0.1) +
  
  geom_text(data = month_from_lag(15, 1), aes(y = Inf, label = month2), 
            size = 2.5,
            vjust = 1) +
  
  geom_text(data = month_from_lag(1, 1), aes(y = -Inf, label = lag), 
            size = 2.5,
            vjust = 0) +
  
  
  geom_ribbon(aes(ymin = low, 
                  ymax = high, 
                  color = version, 
                  fill = version,
                  group = interaction(obs_dataset, version)),
              alpha = 0.1) +
  geom_line(aes(color = version, group = interaction(obs_dataset, version)), linewidth = 1) +
  scale_x_continuous(breaks = NULL) +
  labs(y = "RMSE", 
       x = "Lag") +
  scale_color_models +
  scale_fill_models +
  #   scale_color_models +
  #   scale_fill_models +
  facet_wrap(~ month, labeller = labeller(month = labels_month)) 
```

@fig-rmse shows the median and 95% range of RMSE of sea ice concentration anomalies for +S2 forecasts compared with a benchmark of persistence.
This figure uses +CDR data, but the results are nearly identical compared with ERA5 or Bootstrap.
Due to errors in the initial conditions, it is expected that a persistence forecast would be better than the model forecast at very short lags, but that the persistence forecast errors would grow faster and eventually surpass the mode forecast, at which time is statistically useful {==I've got this from CC at the ICTP summer school and makes sense, but it would be great to have a referece?=
=}.
Here the persistence errors are almost always lower than the +S2 forecast, indicating that the model doesn't have skill at any lag and in any month.
The only exception is the RMSE around Febraury forecasted from June onwards.

{==Add regional?=
=}

### Comparison with S1

```{r fig-iiee}
#| fig-cap: Median and 95% coverage of Integrated Ice Edge Error as a function of forecast lag for all forecast initialised on the first of each month for ACCESS-S1 and ACCESS-S2 hindcasts. 

errors |> 
  _[measure == "iiee"] |>
  _[obs_dataset == which_dataset] |>
  _[, month := lubridate::month(time_forecast, label = TRUE)]  |> 
  _[, median_ci(value), 
    by = .(lag, version, measure, obs_dataset, month(time_forecast))] |> 
  ggplot(aes(lag, mid)) +
  
  geom_vline(data = month_from_lag(1, 1), aes(xintercept = lag), 
             colour = "gray50", linewidth = 0.1) +
  
  geom_text(data = month_from_lag(15, 2), aes(y = Inf, label = month2), 
            size = 2.5,
            vjust = 1) +
  
  geom_text(data = month_from_lag(1, 2), aes(y = -Inf, label = lag), 
            size = 2.5,
            vjust = 0) +
  
  
  geom_ribbon(aes(ymin = low, 
                  ymax = high, 
                  color = version, 
                  fill = version), alpha = 0.1) +
  geom_line(aes(color = version), linewidth = 1) +
  scale_y_continuous(labels = labels_extent) +
  scale_x_continuous(breaks = NULL) +
  scale_color_models +
  scale_fill_models +
  labs(y = NULL, 
       x = "Lag") +
  #   scale_color_models +
  #   scale_fill_models +
  facet_wrap(~ month, labeller = labeller(month = labels_month)) 
```

To compare +S2 with +S1, we computed the IIEE for both models.
This error measure is shown in @fig-iiee for all lags and forecasts initialised at the first of every month.
+S1 has lower error at short lags at all months, with the errors converging as the forecast goes on.
The time to convergence depends on the month and it can be as fas as a few days in July to as large as several months for forecasts initiated in February and March.
Since the only difference between these forecasts are the initial conditions, this timescale is an indication of the the memory of sea ice to initial conditions; at least from October to March when the data assimilated form the other components has little to no influence on sea ice.

Also evident in @fig-iiee is the difference in the error spread at short lags between +S2 and +S1.
In all month +S1 shows a small error spread at lag 1, indicating that the error in the initial conditions not only is small, but also fairly constant.
This spread then grows towards a climatological spread as errors accumulate differently in different forecasts.
For +S2, this is true only only between July and October, approximately.
For all other months, the error spread is more or less stable throughout the forecast window, indicating that not only the initial error is high, but it's not constant.

```{r fig-iiee-variance}
#| fig-cap: Mean spread of IIEE at different lags for different models. 
#| fig.height: 9
#| fig.width: 4
labels_extent_2 <- function(x) {
  m <- which.max(x)
  x <- scales::label_number(scale = (1e-12)^2)(x)
  x[m] <- paste0(x[m], "\nM km⁴")
  x
}

rbind(mean_variance = errors |>
        _[measure == "iiee"] |>
        _[obs_dataset == which_dataset] |>
        _[, var(value, na.rm = TRUE), by = .(version, lag, time_forecast)] |> 
        _[, .(value = mean(V1, na.rm = TRUE)), by = .(version, month(time_forecast), lag)],
      
      variance_of_mean = errors |>
        _[measure == "iiee"] |>
        _[obs_dataset == which_dataset] |>
        _[, mean(value, na.rm = TRUE), by = .(version, lag, time_forecast)] |> 
        _[, .(value = var(V1, na.rm = TRUE)), by = .(version, month(time_forecast), lag)],
      idcol = "component") |> 
  
  ggplot(aes(lag, value)) +
  
  
  geom_vline(data = month_from_lag(1, 1), aes(xintercept = lag), 
             colour = "gray50", linewidth = 0.1) +
  
  geom_text(data = month_from_lag(15, 2), aes(y = Inf, label = month2), 
            size = 2.5,
            vjust = 1) +
  
  geom_text(data = month_from_lag(1, 2), aes(y = -Inf, label = lag), 
            size = 2.5,
            vjust = 0) +
  
  geom_line(aes(color = version), linewidth = 1) +
  scale_y_continuous("Variance", 
                     labels = labels_extent_2) +
  # scale_color_models +
  scale_x_continuous("Lag", breaks = NULL) +
  scale_color_models +
  facet_grid(month ~ component, 
             labeller = labeller(month = labels_month, 
                                 component = c(mean_variance = "Mean variance",
                                               variance_of_mean = "Variance of mean"))) 
```

The large initial error spread could be due either to large spread of ensemble members or due to a large spread of individual forecasts.
@fig-iiee-variance splits the IIEE variance for each lag into the mean variance of each individual forecast and the variance of the mean error of each individual forecast, which adds up to the total variance.
The average variance of each forecast is almost identical between forecast systems in all months.
This shows that the ensemble spread of individual forecasts evolves identically, which, again, it's not unexpected because both systems share the same model formulation.
This also shows that the perturbation scheme in +S2 is comparable to the one in +S1.

On the other hand, the spread of the mean error is always larger in +S2 than +S1.
The difference is particularly large at short lags in some months, which coindice with the ones in which the data assimilation scheme is not influencing sea ice initial conditions.

## Conclusions

# References

::: {#refs}
:::

# Suplementary figures

## ERA5

```{r dataset_era}
which_dataset <- "era5"
```

```{r}
<<fig-hindcast-extent>>
```

```{r}
<<fig-mean-growth>>
```

```{r}
<<fig-bias>>
```

```{r}
<<<fig-extent-anom>>
```

```{r}
<<fig-rmse>>
```

```{r}
<<fig-iiee>>
```

```{r}
<<fig-iiee-variance>>
```

