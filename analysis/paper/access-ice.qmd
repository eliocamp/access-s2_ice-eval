---
title: Evaluation of +S2 sea ice forecast and some other better title
pdf-engine: pdflatex
journal:
  name: tc
author:
  - given_name: Elio 
    surname: Campitelli
    affiliation: "1,2"
    email: elio.campitelli@monash.edu
    corresponding: true
  - given_name: Ariaan 
    surname: Purich
    affiliation: "1,2"
  - given_name: Julie
    surname: Arblaster
    affiliation: "1,2"
  - given_name: Eun-Pa
    surname: Lim
    affiliation: "3"
  - given_name: Matthew
    surname: Wheeler
    affiliation: "3"
  - given_name: Phillip
    surname: Reid
    affiliation: "3"        
  
affiliation:
  - code: 1
    address: School of Earth, Atmosphere and Environment, Monash University, Australia
  - code: 2
    address: Securing Antarctica’s Environmental Future, Monash University, Australia
  - code: 3
    address: Bureau of Meteorology

abstract: |
  The abstract goes here.
  It can also be on _multiple lines_.
bibliography: references.bib
running:
  title: +S2 sea ice forecast
  author: Campitelli et al.
# This section is mandatory even if you declare that no competing interests are present.
competinginterests: |
  The authors declare no competing interests.
# See https://publications.copernicus.org/for_authors/licence_and_copyright.html, normally used for transferring the copyright, if needed. 
# Note: additional copyright statements for affiliated software or data need to be placed in the data availability section. 
copyrightstatement: |
  The author's copyright for this publication is transferred to institution/company. 
### The following commands are for the statements about the availability of data sets and/or software code corresponding to the manuscript.
### It is strongly recommended to make use of these sections in case data sets and/or software code have been part of your research the article is based on.
### Note: unless stated otherwise, software and data affiliated with the manuscript are assumed to be published under the same licence as the article (currently Creative Commons 4.0)
availability:
  #code: |
  #  use this to add a statement when having only software code available
  #data: |
  #  use this to add a statement when having only data sets available
  codedata: |
    use this to add a statement when having data sets and software code available
  sample: |
    use this section when having geoscientific samples available
videosupplement: |
  use this section when having video supplements available
authorcontribution: |
  Contributions
disclaimer: |
  We like Copernicus.
acknowledgements: |
  Acknowledgements will gohere
appendix: |
  \section{Figures and tables in appendices}
  Regarding figures and tables in appendices, the following two options are possible depending on your general handling of figures and tables in the manuscript environment:
  \subsection{Option 1}
  If you sorted all figures and tables into the sections of the text, please also sort the appendix figures and appendix tables into the respective appendix sections.
  They will be correctly named automatically.
  \subsection{Option 2}
  If you put all figures after the reference list, please insert appendix tables and figures after the normal tables and figures.
  
  To rename them correctly to A1, A2, etc., please add the following commands in front of them:
  `\appendixfigures` needs to be added in front of appendix figures
  `\appendixtables` needs to be added in front of appendix tables
  
  Please add `\clearpage` between each table and/or figure.
format: docx

execute: 
  echo: false
  warning: false
  message: false
  cache: true
filters:
  - ../../_extensions/pandoc-ext/abstract-section/abstract-section.lua
  # - ../../_extensions/mloubout/critic-markup/critic-markup.lua
  - ../../_extensions/ute/search-replace/search-replace.lua
search-replace:
  +S2: ACCESS-S2
  +S1: ACCESS-S1
  +CDR: NOAA/NSIDC CDRV4
---

```{r setup, include=FALSE, cache = FALSE}
library(lubridate)
library(ggplot2)
library(data.table)
library(metR)
library(rcdo)
library(tagger)
library(patchwork)

cdo_options_set("-L")
```

```{r helpers, cache = FALSE}
source(here::here("R/functions.R"))
source(here::here("R/datasets.R"))
source(here::here("R/ggplot.R"))
```

# Abstract

balbalbal

# Introduction

Unlike Arctic sea ice, which has been steadily retreating at least since the start of satellite records in the early 80s, Antarctic sea ice has experienced a slightly increasing trend up to 2015. 
This trend puzzled researchers and was not reproduced by models [@hobbs2016].
Then, in 2016 Antarctic sea ice extent dropped precipitously [@turner2017a] and has been at low and record low levels since [@purich2023; @hobbs2024; @gilbert2024; @josey2024], even more highlighting our lack of understanding of Antarctic sea ice variability and long-term change [@espinosa2024].

Antarctic sea ice covers the polar ocean, yet the potential impacts of its variability extend far into the mid and lower latitudes, affecting the circulation of both the ocean and the atmosphere, ocean carbon uptake and biological processes [@fogwill2020, @england2020, @swadling2023].
In coupled climate model experiments, a reduction in sea ice extent has been shown to reduce the meridional temperature gradient, in turn reducing the eddy-driven jet strength and shifting it equatorward [@england2018; @england2020; @ayres2019; @ayres2022] and vice versa for an increase in sea ice [@raphael2003a; @raphael2011], which is a crucial control on extratropical weather.
In the Northern Hemisphere, it has been hypothesised that the reduction in Arctic sea ice has led to a weaker, wavier jet, increasing the frequency of extreme events [@barnes2015; @smith2022]. 
There is some evidence of this effect in the Southern Hemisphere.
For example, model simulations show a weakened vortex in the middle atmosphere, increased vertical wave flux and greater zonal wave 1 amplitude in austral spring following lower than average sea ice extent in early winter [@rea2024, @song2025]. 
But models disagree on the exact phase of the zonal wave response, and observations do not show a clear signal [@rea2024].
The magnitude of the eddy-driven jet response  to sea ice loss has been shown to be model dependent, and is sensitive to its climatological location [@ayres2019].
Further, sea ice induced changes in the jet have been found to be  relatively small compared with the jet-response to the direct effect of CO2 increase and global sea surface temperature (SST) warming [@ayres2022].

Correctly modelling Antarctic sea ice is essential for understanding processes and improving climate projections to inform adaptation strategies.
Accurate seasonal to sub-seasonal forecasts are also crucial for operations in and around the Antarctic continent, including scientific missions, fisheries, and tourism [@desilva2020; @wagner2020].
However, producing accurate Antarctic sea ice forecasts has been challenging due to model biases, inherent large variability and complexity, and it has lagged behind Arctic sea ice forecasts [@zampieri2019].
Dynamical seasonal forecasts of summer Antarctic sea ice have been shown to perform worse than relatively simple statistical methods [@massonnet2023], which also underscores the need for better understanding of sea ice dynamics, and drivers.

In this work we evaluate sea ice forecasts produced by the Australian Community Climate and Earth System Simulator -- seasonal version2 (+S2), which is the Australian Bureau of Meteorology (BoM)'s current operational subseasonal-to-seasonal prediction system, and compare its forecast skill with that of the former system +S1.
This evaluation will inform future work with the prediction system as a research tool and explore the potential of using its sea-ice forecasts for decision-making.

# Data and methods

## +S2

+S2 [@wedd2022] became operational in October 2021 by replacing the +S1 system [@hudson2017]..
The model components of both +S2 and +S1 consist of the Global Atmosphere 6.0 (GA6) [@williams2015; @waters2017], Global Land 6.0 [@best2011; @waters2017], Global Ocean 5.0 [@gurvan2013; @megann2014] and Global Sea Ice 6.0 [CICE; @rae2015].
The atmosphere has a N216 horizontal resolution (\~60km in the mid-latitudes) with 85 vertical levels.
The land model uses the same horizontal grid with 4 soil levels.
The ocean component has a 1/4º resolution with 75 vertical levels.
The sea ice component, based on CICE version 4.1, has the same resolution as the ocean and 5 sea ice categories as well as an open water category.

Both systems take atmospheric initial conditions derived from ERA-interim [@dee2011] for their hindcasts and from the Bureau's operational analysis for real-time forecasts.
The main difference between the two are the ocean and sea ice initial conditions.
+S1 ocean initial conditions come from the Met Office FOAM system, which uses a multivariate, incremental three-dimensional variational (3D-Var), first-guess-at-appropriate-time (FGAT) data assimilation scheme [@waters2015] and assimilates sea surface temperature (SST), sea surface height (SSH), in situ temperature and salinity profiles, and sea ice concentration.
+S2, on the other hand, runs from initial conditions generated by the BoM data assimilation scheme described in @wedd2022.
This scheme is a weakly coupled ensemble optimal interpolation method and assimilates temperature and salinity profiles from EN4 [@good2013] for the hindcasts and from the WMO Global Telecommunication System (GTS) and the Coriolis and USGODAE Global Data Assembly Centers (GDACs) for the real-time forecasts.
SSTs are nudged to Reynolds OISSTv2.1 [@reynolds2007] for the hindcasts and to the Global Australian Multi-Sensor SST Analysis (GAMSSA; Zhong and Beggs 2008) for the real-time forecasts in areas where SSTs are over 0ºC.
Relevant for this work, sea ice concentrations are not assimilated in +S2.

The +S2 hindcast used in this study runs for the period 1981--2018.
Each forecast consists of 9 ensemble members built from three consecutive 3-member forecasts initialised at the first of every month and the two previous days and run from 279 days.
The +S1 hindcast is built in the same manner (albeit with 217-day runs) for the period 1990--2012.

Anomalies for each hindcast are taken with respect to a climatology specific to each initalisation date for the period 1990--2012. 
This serves as a first-order correction of model drift.

## Verification datasets

```{r datasets}
datasets <- list(cdr = CDR(),
                 osi = OSI())
which_dataset <- "cdr"
```

For verification we use satellite-derived estimates of sea ice concentration, which estimates the proportion of each grid area that is covered with ice.
Different datasets derived using different algorithms provide different estimates, each with their own biases and uncertainties.
@meier2019 estimated that the inter-product uncertainty of sea ice extent is of the order of 1 million $km^2$.
As will be shown below, this spread is minimal compared with the typical errors in the +S2 and +S1 forecasts, so the conclusions are independent of the dataset used.

We use NOAA/NSIDC's Climate Data Record V4 [CDR; @meier2014] as the primary verification dataset.
It takes the maximum value of the NASA Team [@cavalieri1984] and NASA Bootstrap [@comiso2023] sea ice concentration products to reduce their low concentration bias [@meier2014; @meier2021].
Both source algorithms use data from the Scanning Multichannel Microwave Radiometer (SMMR) on the Nimbus-7 satellite and from the Special Sensor Microwave/Imager (SSM/I) sensors on the Defense Meteorological Satellite Program's (DMSP) -F8, -F11, and -F13 satellites.
The data has a resolution of 25 by 25 km and daily from 1978 onwards.

The European Organisation for the Exploitation of Meteorological Satellites (EUMETSAT) Ocean and Sea Ice Satellite Application Facility (OSI SAF) [@OSISAF] is another satellite-derived sea ice concentration product.
It is based on mostly the same sensors as the NOAA CDR but computed independently using different algorithms.
Figures prepared with this dataset are provided in the supplementary material and don't differ significantly from the ones prepared using CDR. 

## Error measures

For evaluation purposes, we use a series of measures.

Sea-ice extent is defined as the area of the ocean covered with at least 15% ice.
This threshold is motivated by the limitations in satellite retrieval, which is increasingly unreliable for lower sea ice conditions (cite -- probably something from NSIDC).

Pan-Antarctic (net) sea ice extent serves as a rough hemispheric measure of the amount of sea ice, but it does not take into account the spatial distribution.
A model could have a relatively accurate extent of the net ice but with different regional distributions.
To account for location errors, we computed the Root Mean Squared Error (RMSE) of sea ice concentration anomalies and the Integrated Ice Edge Error [IIEE; @goessling2016].

We compute RMSE as the square root of the average squared differences between forecasted and observed sea ice concentration anomalies.
We compute a pan-Antarctic RMSE by averaging over the whole NOAA/NSIDC CDRV4 southern hemisphere domain, and also a zonally-varying RMSE computed over twenty-four 15° longitude slices around Antarctica.

The IIEE is defined as the area where the model miss-predicts sea ice concentration being above or below 15% ice.
That is, dichotomise sea ice concentration into areas with more and less than 15% sea ice both in the forecast and observations.

All error measures were computed on the NOAA/NSIDC CDRV4 domain grid and projection to which model output was bilinearly interpolated.

# Results and discussion

## Bias

```{r extent_daily}
extent_daily <- datasets |>
  lapply(extent) |>
  lapply(\(x) ReadNetCDF(x, "aice")) |>
  rbindlist(idcol = "dataset") |>
  _[, let(lon = NULL, lat = NULL)]
```

```{r hindcast_extent}
hindcast_extent <- fread(here::here("data/derived/hindcast_extent.csv")) |> 
  _[, model := relevel(factor(model), "S2")] |> 
  _[, lag := as.numeric(as.Date(time) - as.Date(forecast_time))] |> 
  _[lag > 0] |> 
  _[!(month(forecast_time) == 1 & member == 7 & model == "S1")]  # This member is wrong
```

```{r extent_climatology}
ranges <- hindcast_extent[, .(range = list(range(time))), by = model]


extent_climatology <- purrr::pmap(ranges, \(model, range) {
  extent_daily |>  
    _[time %between% range] |> 
    _[aice == 0, aice := NA] |> 
    _[!(month(time) == 2 & mday(time) == 29)] |> 
    _[, time := update(time, year = 2001)] |> 
    _[, median_ci(aice), by = .(time, dataset)] |> 
    _[, model := model] |> 
    _[]
}) |> 
  rbindlist()
```

```{r range_max_lag}
range_max_lag <- hindcast_extent[mday(time) == 2, .SD[which.max(lag)], by = .(forecast_time, model)] |> 
  _[, .(max = max(lag),
        min = min(lag)),
    by = model]
```

```{r fig-hindcast-extent}
#| fig-cap: Pan-Antarctic median sea ice extent for al hindcasts initialised the first of the month for +S2 and +S1 in colours representing the start month with the median sea ice extent of +CDR in the left column and the median difference in the right column. The +CDR climatology is computed in the period corresponding to each hindcast. Circles represent the initial conditions at the first of every month and triangles represent the median value at the first of every month forecasted with the largest possible lead time. Colours indicate the initialisation month of the forecast. 

hindcast_bias_extent <- hindcast_extent |> 
  _[, median_ci(aice), by = .(forecast_time = update(forecast_time, year = 2001),
                              lag = as.numeric(as.Date(time) - forecast_time),
                              model)] |> 
  _[, time := forecast_time + lag] |>
  _[, time2 := update(time, year = 2001)] |>
  _[, month := lubridate::month(forecast_time, label = TRUE)] |> 
  ggplot(aes(time2, mid)) +
  geom_line(data = extent_climatology[dataset == which_dataset], 
            aes(x = as.Date(time),
                group = dataset)) + 
  geom_line(aes(color = month, group = interaction(forecast_time, time != time2))) +
  
  geom_point(data = \(x) x[mday(time) == 2, .SD[which.max(lag)], by = .(forecast_time, model)], 
             aes(fill = month), 
             shape = 24, size = 2.2) +
  
  geom_point(data = \(x) x[lag == 1], aes(fill = month), 
             shape = 21, size = 2) +
  
  scale_x_date(NULL, date_breaks = "1 month", 
               date_labels = "%b", expand = c(0, 0)) +
  scale_y_continuous(NULL, labels = labels_extent) +
  scale_color_manual(values = cetcolor::cet_pal(12, name = "c2"), 
                     aesthetics = c("fill", "color"), guide = "none") +
  facet_wrap(~ model, ncol = 1, labeller = labeller(model = labels_models)) +
  tag_facets() 

hindcast_bias_extent_dif <- copy(hindcast_bias_extent)


hindcast_bias_extent_dif$layers[[1]] <- geom_hline(yintercept = 0) 
hindcast_bias_extent_dif$data <- extent_daily[hindcast_extent, on = c("time")] |> 
  _[, median_ci(i.aice - aice), 
    by = .(forecast_time = update(forecast_time, year = 2001),
           lag = as.numeric(as.Date(time) - forecast_time),
           model)] |> 
  _[, time := forecast_time + lag] |>
  _[, time2 := update(time, year = 2001)] |>
  _[, month := lubridate::month(forecast_time, label = TRUE)] 

hindcast_bias_extent +
  hindcast_bias_extent_dif

```

@fig-hindcast-extent a shows the median sea ice extent (left column) and median difference with respect of +CDR for the +S2 and +S1 hindcasts (right column).
Median extent of initial conditions at the first of every month are indicated with circles, while median extent at the same date but forecasted with the largest lead time possible for each model (between `r range_max_lag[model == "S2", min]` and `r range_max_lag[model == "S2", max]` days for +S2 and between `r range_max_lag[model == "S1", min]` and `r range_max_lag[model == "S1", max]` days for +S1).
At this large lead time, the the information of the initial conditions is essentially lost and the forecast reverts to each model's preferred equilibrium state.

+S2 initial conditions (circles) show an overall negative bias, especially in the late summer-early autumn, while +S1 initial conditions are very close to observations.
Both models' equilibrium state (triangles) show a negative bias of sea ice extent, particularly in the late-autumn and winter months.
This is due primarily to faster melt during a longer melt season between January and March and slower growth during March and April.
This is then partially balanced with faster growth between May and July ([Fig. @fig-mean-growth]).
Many sea ice models exhibit this systematic underestimation during the sea ice minimum and early freezing season [@massonnet2023] and could indicate problems in the representation of thermodynamics in the model [@zampieri2019].
It is not surprising that both forecasting systems converge to a similar climatology because they share the same model formulation.

The difference between the initial conditions and the model preferred state can be attributed to the effect of data assimilation, which in +S2 is due solely to atmospheric and oceanic data assimilation.
From June to October, in +S2 circles are closer to observations than to the triangles, indicating that the information from the ocean and atmosphere data assimilation is affecting sea ice and improving the initial conditions.
The rest of the year there is little if any difference between circles and triangles in +S2, indicating that the ocean and atmosphere data assimilation is not affecting sea ice and that this component of the model is virtually free-running.

```{r extent-delta-compute}
dif_hindcast <- hindcast_extent |> 
  copy() |> 
  _[order(time)] |> 
  _[, dif := c(NA, diff(aice)/diff(as.numeric(as.Date(time)))), by = .(model, forecast_time, member)] |> 
  _[, median_ci(dif), by = .(model, time = update(time, year = 2000))] 


dif_hindcast <- rbind(
  dif_hindcast |> 
    copy() |> 
    _[, time := update(time, year = 1999)],
  dif_hindcast,
  dif_hindcast |> 
    copy() |> 
    _[, time := update(time, year = 2001)]
)


dif_extent <- extent_daily |> 
  _[order(time)] |> 
  _[, dif := c(NA, diff(aice)/diff(as.numeric(as.Date(time)))), by = .(dataset)] |> 
  _[, median_ci(dif), by = .(dataset, time = update(time, year = 2000))] |> 
  _[dataset == which_dataset]

dif_extent <- rbind(
  dif_extent |> 
    copy() |> 
    _[, time := update(time, year = 1999)],
  dif_extent,
  dif_extent |> 
    copy() |> 
    _[, time := update(time, year = 2001)]
)
```

```{r fig-mean-growth}
#| fig-cap: Median daily sea ice extent growth of +S1 and +S2 hindcasts and observations computed as the median daily differences in sea ice extent for each date and all lead times. Values are smoothed with a 11-day running mean. 

n <- 366*3
w <- 11
dif_extent |> 
  copy() |> 
  _[, mid := frollmean(mid, n = w, align = "center"), by = dataset] |> 
  ggplot(aes(time, mid)) +
  geom_hline(yintercept = 0, color = "gray50", linewidth = 0.2) +
  geom_line(aes(color = dataset)) +
  # geom_smooth(aes(group = dataset, color = dataset), 
  #             method = "loess",
  #             span = w/n, linewidth = 0.5, se = FALSE, n = n)  +
  # geom_line() +
  
  geom_line(data = dif_hindcast |> 
              copy() |> 
              _[, mid := frollmean(mid, n = w, align = "center"), by = model],
            aes(color = model)) +
  # geom_smooth(data = dif_hindcast,
  #             method = "loess",
  #             aes(color = model), span = w/n, linewidth = 0.5, se = FALSE, n = n) +
  scale_x_datetime(NULL, date_breaks = "1 month", 
                   date_labels = "%b", expand = c(0, 0)) +
  scale_y_continuous(NULL, labels = \(x) labels_extent(x, units = "M km²/day")) +
  scale_color_models +
  coord_cartesian(xlim = as.POSIXct(c("2000-01-01", "2000-12-31"), tz = "UTC"))
```

```{r hindcast_clim}
zeropad <- function(x, n = 2) formatC(x, width = 2, flag = "0")
monnb <- function(d) { lt <- as.POSIXlt(as.Date(d, origin="1900-01-01")); 
lt$year*12 + lt$mon } 
mondf <- function(d1, d2) { monnb(d2) - monnb(d1) }

months <- 1:12

hindcast_clim <- lapply(setNames(months, months), \(month) {
  here::here(glue::glue("data/derived/climatology/S2/{zeropad(month)}/em.nc")) |> 
    cdo_selmonth(month) |> 
    cdo_execute() |> 
    ReadNetCDF("aice")
}) |> 
  rbindlist(idcol = "forecast_month") |> 
  _[, forecast_month := as.numeric(forecast_month)]


hindcast_clim <- hindcast_clim |> 
  copy() |> 
  _[, .(aice = mean(aice)), by = .(month(time), ygrid, xgrid, forecast_month)] |> 
  _[forecast_month == month]


obs_clim <- CDR() |> 
  climatology() |> 
  cdo_ymonmean() |>
  cdo_execute() |> 
  ReadNetCDF(c(obs = "aice")) |> 
  _[, month := month(time)]

hindcast_clim <- hindcast_clim |> 
  merge(obs_clim)
```

```{r fig-bias}
#| fig-width: 9
#| fig-height: 6
#| fig-cap: Mean difference between monthly sea ice concentrations at 0-month lead time +S2 forecast and observations. 

ice_shelves_nsicd <- fread(here::here("data/derived/antarctic_ice_shelves_nsidc.csv"))

hindcast_clim |> 
  # dcast(time + xgrid + ygrid ~ model, value.var = "aice") |> 
  # setnames(which_dataset, "obs") |>
  ggplot(aes(xgrid, ygrid)) +
  geom_contour_fill(aes(z = aice - obs, fill = after_stat(level)), 
                    breaks = AnchorBreaks(binwidth = 0.1, exclude = 0)) +
  scale_fill_divergent_discretised(paste0("Bias with respect to ",
                                          labels_models[which_dataset]),
                                   low = trans_pink,
                                   high = trans_blue) +
  # geom_polygon(data = ice_shelves_nsicd, aes(X, Y, group = group), 
  #              colour = "black", fill = "#FAFAFA") +
  geomcoord_antarctica +
  geom_antarctica_fill +
  facet_wrap(~ month, labeller = labeller(month = labels_month)) +
  wide_legend +
  tag_facets()
```

@fig-bias shows the difference of monthly mean sea ice concentrations between NOAA/NSIDC CDRV4 and +S2 hindcasts at the shortest lead time
From October to May, the model underestimates sea ice concentrations in most regions except for the inner Weddell Sea in April and May, where sea ice concentrations saturate to 1 both in the observations and forecasts.
In winter, the differences are mostly on the sea ice edge with light positive bias in the African sector of East Antarctica and negative bias around the Indian Ocean sector which partially compensate, resulting in the near-zero extent bias seen in those months ([Fig. @fig-hindcast-extent]).

## RMSE

```{r fig-extent-anom}
#| fig-cap: Monthly mean sea ice extent anomalies for +S1 and +S2 and observations (black) forecasted at selected lead times. The RMSE during the overlapping period (1990--2013) is shown on the top left. 

months_difference <- function(x, y) {
  lubridate::interval(y, x) %/% months(1)
}

monthly_extent <- extent_daily |> 
  _[dataset == which_dataset] |> 
  _[aice == 0, aice := NA]  |> 
  _[, .(aice = mean(aice)), by = .(dataset, time = as.Date(round_date(time, "month")))] |>
  _[, aice := Anomaly(aice, year(time) %between% c(1981, 2011), na.rm = TRUE), 
    by = .(month(time), dataset)] 

N <- uniqueN(monthly_extent$time)

s1_range <- hindcast_extent[model == "S1"][, range(time)]
s2_range <- hindcast_extent[model == "S2"][, range(time)]

hindcast_extent |> 
  copy() |> 
  _[, aice := aice - mean(aice[year(time) %between% c(1981, 2011)]), 
    by = .(lag, model, time = update(time, year = 2000))] |> 
  _[, .(forecast = mean(aice)), by = .(model, forecast_time, time = as.Date(round_date(time, "month")))] |> 
  _[, lag := months_difference(time, forecast_time)] |> 
  _[, merge(.SD, monthly_extent, all = TRUE), by = .(model, lag)] |> 
  _[lag %in% (c(1, 3, 5, 7) - 1)] |>
  _[time %between% s2_range] |> 
  ggplot(aes(time)) +
  geom_line(aes(y = aice, group = dataset, color = dataset)) +
  geom_line(aes(y = forecast, color = model))  +
  geom_text(data = \(x) x[time %between% s1_range, 
                          .(text = sqrt(mean((aice - forecast)^2, na.rm = TRUE))), 
                          by = .(lag, model)],
            aes(label = paste0(scales::number(text, scale = 1e-12), " M km²")), x = -Inf, y = Inf,
            vjust = 1.2, hjust = -0.2) +
  scale_y_continuous(NULL,
                     labels = labels_extent) +
  scale_x_date(NULL, expand = c(0, 0)) +
  facet_grid(lag ~ model, labeller = labeller(lag = \(x) paste0("Month: ", x))) +
  scale_color_models
```

@fig-extent-anom shows monthly sea ice extent anomalies forecasted at selected lead times.
Compared with +S1, +S2 anomaly forecast is relatively poor even in the first month, which stays relatively skilful even at a lead time of 3 months.
+S2 shows much bigger variability than observations, with dramatic lows between 1995 and 2007 and highs between 2007 and 2015.

To assess +S2 forecasts quantitatively, we compute error measures for all hindcasts started on the 1st of every month.

```{r errors}
errors <- rbind(
  readRDS(here::here("data/derived/rmse.Rds")),
  readRDS(here::here("data/derived/iiee.Rds"))
) |> 
  _[value < 0.01, value := NA] |> 
  _[value > 3e13, value := NA] |> 
  _[, time := as.Date(time)] |> 
  _[, lag := as.numeric(time - time_forecast)] |> 
  _[lag > 0] |> 
  _[!(month(time_forecast) == 1 & member == "07" & version == "S1")]  # This member is wrong

```

```{r clim_std}
clim_std <- datasets |> 
  lapply(\(x) x |> 
           anomalies() |> 
           cdo_sqr() |> 
           cdo_fldmean() |> 
           cdo_sqrt() |> 
           cdo_execute() |> 
           ReadNetCDF(c(climatology = "aice")) |> 
           _[, let(lat = NULL, lon = NULL)]
  ) |> 
  rbindlist(idcol = "obs_dataset") |> 
  _[, time := as.Date(time)] |> 
  _[climatology == 0, climatology := NA] |> 
  _[climatology < 0.05, climatology := NA] 

```

```{r clim_std2}
clim_std2 <- clim_std[errors, on = .NATURAL] |> 
  _[, let(climatology = NULL,
          value = climatology)] |> 
  na.omit() |> 
  _[, version := "climatology"]
```

```{r fig-rmse}
#| fig-cap: Median RMSE of sea ice concentration anomalies as a function of forecast lead time for all forecast initialised on the first of each month compared with a reference forecast of persistence of anomalies (black) and climatology (gray).
#| fig.height: 5
#| fig.width: 9

month_from_lag <- function(day = 1, step = 2) {
  force(day)
  force(step)
  function(x) {
    unique(x[, .(lag, month)])[, time := make_date(month = month, day = 1) + lag] |> 
      _[mday(time) == day, .(lag, month, 
                             month2 = lubridate::month(time, label = TRUE)
      )] |> 
      _[, .SD[((seq_len(.N) + 1) %% step) == 0], by = month]
  }
}

clim_std2 |> 
  rbind(errors) |>
  _[measure == "rmse"] |>
  _[, time2 := update(time, year = 2000)] |> 
  # merge(clim_std) |>
  _[obs_dataset ==  which_dataset] |>
  _[, median_ci(value),
    by = .(lag, version, measure, month(time_forecast), obs_dataset)] |>
  ggplot(aes(lag, mid)) +
  
  geom_vline(data = month_from_lag(1, 1), aes(xintercept = lag), 
             colour = "gray50", linewidth = 0.1) +
  
  geom_text(data = month_from_lag(15, 1), aes(y = Inf, label = month2),
            size = 2.5,
            vjust = 1) +
  
  geom_text(data = month_from_lag(1, 1), aes(y = -Inf, label = lag), 
            size = 2.5,
            vjust = 0) +
  
  # geom_ribbon(aes(ymin = low, 
  #                 ymax = high, 
  #                 color = version, 
  #                 fill = version,
  #                 group = interaction(obs_dataset, version)),
  #             alpha = 0.1) +
  geom_line(aes(color = version, group = interaction(obs_dataset, version)), linewidth = 1) +
  
  # geom_line(aes(y = clim_std)) +
  scale_x_continuous(breaks = NULL, expand = c(0, 0)) +
  labs(y = "RMSE", 
       x = "Lead time (days)") +
  scale_color_models +
  scale_fill_models +
  facet_wrap(~ month, labeller = labeller(month = labels_month)) 
```

@fig-rmse shows the median RMSE of sea ice concentration anomalies for +S2 and +S1 hindcasts compared with a benchmark of persistence and climatology.
Due to errors in the initial conditions, it is expected that a persistence forecast would be better than the model forecast at very short lead times, but that the persistence forecast errors would grow faster and eventually surpass the model forecast, after when the model is statistically useful.
Here the persistence errors are almost always lower than the +S2 forecast, indicating that the model does not have skill at any lead time and in any month.
The only exception is around February, where the model has lower RMSE than the persistence forecast at virtually every lead time.


```{r topo_lonlat}
topo_lonlat <- here::here("data/raw/ETOPO.nc") |> 
  ReadNetCDF() |> 
  na.omit() 
```

```{r rmse_lon_mean}
rmse_lon_mean <- here::here("data/derived/rmse_lon.Rds") |> 
  readRDS() |> 
  _[version != "S1"] |> 
  _[, lag := as.numeric(as.Date(time) - time_forecast)] |> 
  _[, base := value[version == "persistence"], 
    by = .(time, lon, lag, obs_dataset)] |> 
  _[version != "persistence"] |>
  _[, .(dif = median(value - base, na.rm = TRUE)),
    by = .(lag, lon, version, obs_dataset, month = factor(month(time_forecast)))]
```

```{r fig-rmse_lon, fig.height=7, fig.width=10}
#| fig.cap: Median difference between RMSE of +S2 forecasts and persistence forecast computed on `r uniqueN(rmse_lon_mean$lon)` meridional slices `r diff(unique(rmse_lon_mean$lon))[1]`º wide. Antarctica's coastline is shown at the bottom of each panel for reference. 

binwidth <- 0.015

rmse_lon_mean |> 
  _[obs_dataset == which_dataset] |> 
  ggperiodic::periodic(lon = c(0, 360)) |> 
  ggplot(aes(lon, lag)) +
  geom_contour_fill(aes(z = dif, fill = after_stat(level)),
                    breaks = AnchorBreaks(0, exclude = 0, binwidth = binwidth))  +
  geom_contour_tanaka(aes(z = dif), range = c(0.01, 0.4),
                      breaks = AnchorBreaks(0, exclude = 0, binwidth = binwidth)) +
  
  geom_contour_fill(data = topo_lonlat,
                    aes(lon, scales::rescale(lat, c(-60, 1)), 
                        z = z, 
                        fill = NULL),
                    fill = "#FAFAFA",
                    breaks = c(0, Inf)) +
  
  geom_contour2(data = topo_lonlat,
                aes(lon, scales::rescale(lat, c(-60, 1)), z = z),
                breaks = 0) +
  geom_hline(data = month_from_lag(1, 1), aes(yintercept = lag),
             colour = "gray50", linewidth = 0.1) +
  
  geom_text(data = month_from_lag(15, 1), aes(x = 361, label = month2),
            size = 2.5, 
            hjust = 0) +
  
  geom_text(data = month_from_lag(1, 1), aes(x = -2, label = lag),
            size = 2.5,
            hjust = 1) +
  scale_fill_divergent_discretised(low = trans_blue, high = trans_pink) +
  scale_x_longitude(ticks = 60, expand = c(0.08, 0)) +
  
  scale_y_continuous(breaks = NULL, expand = c(0, 0)) +
  labs(fill = NULL, 
       y = "Lead time (days)") +
  wide_legend +
  facet_wrap(~ month, labeller = labeller(month = labels_month)) +
  theme(panel.background = element_blank(), panel.grid = element_blank(),
        tagger.panel.tag.background = element_rect(colour = "white", fill = "white")) +
  tag_facets(position = list(x = 0.08, y = 1, hjust = 0, vjust = 1))
```

Even though +S2 is no better than persistence at forecasting pan-Antarctic sea ice concentration anomalies, the quality of the forecast might vary between regions.
To analyse the spatial distribution of the model error, we computed sea ice concentration anomalies RMSE on `r uniqueN(rmse_lon_mean$lon)` meridional slices `r diff(unique(rmse_lon_mean$lon))[1]`º wide.
The median difference between the forecast and persistence RMSE is shown on @fig-rmse_lon, where negative values indicate that the model has lower RMSE than the benchmark.

The skill shown by +S2 at February-March forecasts is observed 

by a band of negative values across almost all longitudes.
The only region where February-March sea ice is not well forecasted is east of the Antarctic Peninsula, which is the only region with consistent summer sea ice.
This suggests that the positive skill around the summer minimum comes from the model correctly forecasting no ice where no ice is ever found.
However, there are other regions of skilful forecasts.

Forecasts initialised on January 1st ([Fig. @fig-rmse_lon] panel a) show RMSE values below persistence at lead times larger than 180 days (corresponding to July through September) in the Ross and Weddell Sea.
These two regions are also relatively well forecasted from other months.
Notably, May forecasts of Weddell sea ice concentration anomalies ([Fig. @fig-rmse_lon] panel e) are skilful after about 20 days and remain so until December.
The Weddell Sea is also the region with the maximum error --around June regardless of initialisation date.

### Comparison with S1

```{r t_test}
t_test <- function(x, y, ...) {
  
  test <- t.test(x, y, ...)
  
  list(low = test[["conf.int"]][1],
       high = test[["conf.int"]][2], 
       estimate = -diff(test$estimate), 
       p.value = test[["p.value"]]
  )
}

max_lag <- errors[version == "S1", max(lag)]

dif <- errors |> 
  na.omit() |> 
  _[obs_dataset == which_dataset] |>
  _[measure == "iiee"] |> 
  _[version != "persistence"] |> 
  _[lag <= max_lag] |> 
  dcast(time + time_forecast + member + lag ~ version, value.var = "value") |> 
  _[, t_test(na.omit(S1), na.omit(S2)), 
    by = .(lag, month(time_forecast))] |> 
  _[p.value > 0.01] |> 
  _[, .SD[which.min(lag)], by = month] |> 
  _[order(month), .(month, lag)]

labels_month_significant <- setNames(paste0(month.abb, " (", dif$lag, ")"),
                                     1:12)
```

```{r fig-iiee}
#| fig-cap: Median and 95% coverage of Integrated Ice Edge Error as a function of forecast lead time for all forecast initialised on the first of each month for +S1 and +S2 hindcasts. For each month, the number in parenthesis indicates the minimum lead time at which the mean error of each model is not statistically significant at a 1% level using a two-sided t-test. 

errors |> 
  _[measure == "iiee"] |>
  _[obs_dataset == which_dataset] |>
  # _[, month := lubridate::month(time_forecast, label = TRUE)]  |> 
  _[, median_ci(value), 
    by = .(lag, version, measure, obs_dataset, month(time_forecast))] |> 
  ggplot(aes(lag, mid)) +
  
  geom_vline(data = month_from_lag(1, 1), aes(xintercept = lag), 
             colour = "gray50", linewidth = 0.1) +
  
  geom_text(data = month_from_lag(15, 2), aes(y = Inf, label = month2), 
            size = 2.5,
            vjust = 1) +
  
  geom_text(data = month_from_lag(1, 2), aes(y = -Inf, label = lag), 
            size = 2.5,
            vjust = 0) +
  
  geom_ribbon(aes(ymin = low, 
                  ymax = high, 
                  color = version, 
                  fill = version), alpha = 0.1) +
  geom_line(aes(color = version), linewidth = 1) +
  
  
  # geom_errorbar(data = \(x) x[dif, on = .NATURAL][version == "S1"], 
  #              aes(x = lag, 
  #                  ymin = mid - (high - low), ymax = mid + (high - low))) +
  
  # geom_point(data = \(x) x[dif, on = .NATURAL][version == "S1"],
  # aes(lag, mid), size = 3, shape = 21) +
  
  
  scale_y_continuous(labels = labels_extent) +
  scale_x_continuous(breaks = NULL, expand = c(0, 0)) +
  scale_color_models +
  scale_fill_models +
  labs(y = NULL, 
       x = "Lead time (days)") +
  #   scale_color_models +
  #   scale_fill_models +
  facet_wrap(~ month, labeller = labeller(month = labels_month_significant)) 
```

To compare +S2 with +S1, we computed the IIEE for both models.
This error measure is shown in @fig-iiee for forecasts initialised at the first of every month at all lead times.
+S1 has lower error at lead times up to 60 days at all months, with the errors converging to +S2 as the forecast goes on.
The time to convergence depends on the month and it can be as short as two weeks June and July to as long as 160 days for forecasts initialised in February.
Since the only difference between these forecasts are the initial conditions, this timescale is an indication of the memory of sea ice to initial conditions --at least from October to March when the data assimilated from the other components has little to no influence on sea ice.

Also evident in @fig-iiee is the difference in the error spread at short lead times between +S2 and +S1.
In all months +S1 has much narrower error spread at the first day of the forecasts.
The error in the initial conditions is not only small, but also fairly constant.
This spread then grows towards a climatological spread as errors accumulate differently in different forecasts.
For +S2, this is true only between July and October.
For all other months, the error spread is more or less stable throughout the forecast window, indicating that not only the initial error is high, but it is not constant.

```{r fig-iiee-variance}
#| fig-cap: Mean spread of IIEE at different lead times for different models. 
#| fig.height: 6
#| fig.width: 8
labels_extent_2 <- function(x) {
  m <- which.max(x)
  x <- scales::label_number(scale = (1e-12)^2)(x)
  x[m] <- paste0(x[m], "\nM km⁴")
  x
}

rbind(mean_variance = errors |>
        _[measure == "iiee"] |>
        _[obs_dataset == which_dataset] |>
        _[, var(value, na.rm = TRUE), by = .(version, lag, time_forecast)] |> 
        _[, .(value = mean(V1, na.rm = TRUE)), by = .(version, month(time_forecast), lag)],
      
      variance_of_mean = errors |>
        _[measure == "iiee"] |>
        _[obs_dataset == which_dataset] |>
        _[, mean(value, na.rm = TRUE), by = .(version, lag, time_forecast)] |> 
        _[, .(value = var(V1, na.rm = TRUE)), by = .(version, month(time_forecast), lag)],
      idcol = "component") |> 
  
  ggplot(aes(lag, value)) +
  
  
  geom_vline(data = month_from_lag(1, 1), aes(xintercept = lag), 
             colour = "gray50", linewidth = 0.1) +
  
  geom_text(data = month_from_lag(15, 2), aes(y = Inf, label = month2), 
            size = 2.5,
            vjust = 1) +
  
  geom_text(data = month_from_lag(1, 2), aes(y = -Inf, label = lag), 
            size = 2.5,
            vjust = 0) +
  
  geom_line(aes(color = version), linewidth = 1) +
  scale_y_continuous("Variance", 
                     labels = labels_extent_2) +
  # scale_color_models +
  scale_x_continuous("Lead time (days)", breaks = NULL) +
  scale_color_models +
  ggh4x::facet_nested_wrap(month ~ component, ncol = 6, 
                           remove_labels = "all",
                           labeller = labeller(month = labels_month, 
                                               component = c(mean_variance = "Mean variance",
                                                             variance_of_mean = "Variance of mean"))) 
```

The large initial error spread could be due either to large spread of ensemble members or to large spread of individual forecasts.
@fig-iiee-variance splits the IIEE variance for each lead time into the mean variance of each individual forecast and the variance of the mean error of each individual forecast, which adds up to the total variance.
The average variance of each forecast is almost identical between the two forecast systems in all months.
This shows that the ensemble spread of individual forecasts evolves identically, which, again, is not unexpected because both systems share the same model formulation.
This also shows that the perturbation scheme in +S2 is comparable to the one in +S1.

On the other hand, the spread of the mean error is always larger in +S2 than +S1.
The difference is particularly large at short lead times in some months, which coincide with the ones in which the data assimilation scheme is not influencing sea ice initial conditions.

## Conclusions

Sea ice forecasts from the +S2 model show a significant low extent bias, particularly during late summer and early autumn.
This bias is attributed to a faster and longer melt season between January and March, and slower growth between March and April.
This underestimation during the minimum and early freezing season is a common issue in many seasonal-to-subseasonal (S2S) systems, suggesting potential problems either with the model's thermodynamic representation or with short wave radiation forcing, as shown in other climate models [@zampieri2019; @roach2020].
Even though +S2 shares the same model formulation with +S1, the latter does not suffer from this bias.
This is due to the assimilation of sea ice concentrations into the initial conditions, which successfully corrects for the negative bias in the model.
Our analysis suggests that the data assimilation system in +S2 is only effectively influencing sea ice initial conditions from June to October, while the rest of the year, the sea ice component runs virtually free, reverting to its biased equilibrium state.

Analysis of the error spread shows that +S2 initial conditions from December to May not only have large errors, but that the initial error spread is very large compared with +S1.
This spread is not due to the perturbation scheme, since the mean error variance for individual forecasts is low and comparable with +S1.
Instead, it is due to large variance of the mean error of individual forecasts, which is comparable to the climatology spread.
This is further evidence that individual initial conditions are not being affected by the data assimilation scheme.

Based on the observation that +S2 sea ice initial conditions are essentially not initialised, comparing its forecasts with +S1's allows us to estimate the time-scale for which initial conditions are important.
This highlights February initial conditions as crucial for determining sea ice evolution at least up to late June.
Arctic sea ice forecasts also show greater sensitivity to initial conditions in boreal summer compared with boreal winter [@day2014; @bunzel2016], so a similar mechanism might be playing a role.

Although forecasts are not skilful for forecasting pan-Antarctic sea ice concentrations, there are some areas where the model does show skill.
The Weddell Sea, and the Ross Sea to a lesser extent are particularly well forecasted between June and November for forecasts initialised from January to June.
These regions have been recognised as a region of high predictability thanks to persistent and eastwardly advected upper ocean heat content anomalies [@bushuk2021].
Sea surface temperatures are assimilated by +S2 only in areas with temperatures greater than 0°C and errors don't show a clear easterly-propagating signal, so it is not clear if +S2 is leveraging the same source of predictability..

------------------------------------------------------------------------

# References

::: {#refs}
:::

# Supplementary figures

<!-- ## ERA5 -->

<!-- ```{r dataset_era} -->

<!-- which_dataset <- "era5" -->

<!-- ``` -->

<!-- ```{r fig-hindcast-extent-era5} -->

<!-- which_dataset <- "era5" -->

<!-- <<fig-hindcast-extent>> -->

<!-- ``` -->

<!-- ```{r fig-hindcast-extent-bt} -->

<!-- which_dataset <- "bt" -->

<!-- <<fig-hindcast-extent>> -->

<!-- ``` -->

<!-- ```{r fig-mean-growth} -->

<!-- <<fig-mean-growth>> -->

<!-- ``` -->

<!-- ```{r} -->

<!-- <<fig-bias>> -->

<!-- ``` -->

<!-- ```{r} -->

<!-- <<<fig-extent-anom>> -->

<!-- ``` -->

<!-- ```{r} -->

<!-- <<fig-rmse>> -->

<!-- ``` -->

<!-- ```{r} -->

<!-- <<fig-iiee>> -->

<!-- ``` -->

<!-- ```{r} -->

<!-- <<fig-iiee-variance>> -->

<!-- ``` -->
